# üîÑ Provider Switching Guide

## How to Switch LLM Providers (Zero Code Changes!)

Your FastAPI app now uses the **Factory Pattern** with a **config-driven** approach.
Switching providers is as simple as editing a YAML file!

---

## ‚úÖ Current Setup

```yaml
# analytics-assistance/config.yaml
llm:
  provider: groq  # ‚Üê Currently using Groq (FREE!)
  model: llama-3.3-70b-versatile
  temperature: 0.1
  max_tokens: 500
```

**Result:** All API calls use Groq's Llama model

---

## üîÑ Switch to OpenAI

### Step 1: Edit config.yaml

```yaml
# analytics-assistance/config.yaml
llm:
  provider: openai  # ‚Üê Changed from "groq" to "openai"
  model: gpt-4o-mini
  temperature: 0.1
  max_tokens: 500
```

### Step 2: Ensure API key is in .env

```bash
# .env file
OPENAI_API_KEY=sk-...
```

### Step 3: Restart FastAPI

```bash
# Stop current server (Ctrl+C)
# Restart:
cd analytics-assistance
python3 app/main.py
```

### Step 4: Test it!

```bash
curl -X POST http://localhost:8000/api/analyze/columns \
  -H "Content-Type: application/json" \
  -d '{
    "table_name": "crm_customers",
    "requirement": "Show me average MRR by industry"
  }'
```

**That's it!** Now all API calls use OpenAI!

---

## üöÄ Switch to Another Provider (e.g., Anthropic)

When you add Anthropic provider:

### Step 1: Create provider

```python
# llm/providers/anthropic_provider.py
class AnthropicProvider(BaseProvider):
    def generate(self, prompt):
        # Anthropic API call
        ...
```

### Step 2: Register in factory

```python
# llm/model_factory.py
_PROVIDERS["anthropic"] = AnthropicProvider
```

### Step 3: Update config.yaml

```yaml
llm:
  provider: anthropic  # ‚Üê Just change this!
  model: claude-3-5-sonnet-20241022
```

### Step 4: Restart & Done!

No code changes in your main app!

---

## üìä Comparison

### Before (Hardcoded OpenAI):
```python
# To switch from OpenAI to Groq:
# 1. Find all OpenAI imports
# 2. Replace with Groq imports
# 3. Update API calls
# 4. Handle different response formats
# 5. Update error handling
# 6. Test everything
# 7. Deploy
```

**Time:** Hours  
**Risk:** High (breaking changes)  
**Code changes:** Dozens of files

### After (Factory Pattern):
```yaml
# To switch from OpenAI to Groq:
provider: groq  # ‚Üê Change ONE line
```

**Time:** 30 seconds  
**Risk:** Zero (interface is identical)  
**Code changes:** ONE line in YAML

---

## üéØ Benefits of This Architecture

1. **Config-Driven:** One YAML file controls everything
2. **Zero Code Changes:** Switch providers without touching code
3. **Easy Testing:** Test with free Groq, deploy with paid OpenAI
4. **Cost Optimization:** Use cheapest provider for dev, best for prod
5. **Vendor Independence:** Never locked into one provider
6. **Easy Maintenance:** Add new providers without touching core logic

---

## üß™ Test Different Providers

```bash
# Test with Groq (fast & free)
# Edit config.yaml: provider: groq
./test_api_endpoint.sh

# Test with OpenAI (high quality)
# Edit config.yaml: provider: openai
./test_api_endpoint.sh

# Results should be similar, but:
# - Groq: Fast, free, good quality
# - OpenAI: Slower, paid, best quality
```

---

## üîç How It Works Under the Hood

```
User makes API call
    ‚Üì
FastAPI ‚Üí column_planner.py
    ‚Üì
get_llm() function
    ‚Üì
ModelProvider_from_yaml("config.yaml")
    ‚Üì
Factory reads YAML
    ‚Üì
Factory creates correct provider (Groq/OpenAI/etc.)
    ‚Üì
Returns provider instance with common interface
    ‚Üì
App calls provider.generate(prompt)
    ‚Üì
Provider handles API specifics internally
    ‚Üì
Response returned to user
```

**Key:** App only sees `BaseProvider` interface, doesn't care which provider is used!

---

## üéì Architecture Pattern

This is called the **Abstract Factory Pattern**:

- **BaseProvider** = Abstract interface (contract)
- **OpenAIProvider, GroqProvider** = Concrete implementations
- **ModelProvider** = Factory function
- **config.yaml** = Configuration (determines which implementation to use)

**Result:** Loose coupling, high cohesion, easy to extend!

---

## üìù Adding a New Provider Checklist

1. [ ] Create `llm/providers/new_provider.py`
2. [ ] Inherit from `BaseProvider`
3. [ ] Implement `generate(self, prompt)` method
4. [ ] Implement `generate_stream(self, prompt)` method
5. [ ] Register in `model_factory.py`: `_PROVIDERS["new_provider"] = NewProvider`
6. [ ] Add API key to `.env`: `NEW_PROVIDER_API_KEY=...`
7. [ ] Update `config.yaml`: `provider: new_provider`
8. [ ] Test: `./test_api_endpoint.sh`

**That's it!** Main app automatically uses it!

---

## üéâ Summary

**You now have a production-ready, scalable, provider-agnostic LLM architecture!**

- ‚úÖ Switch providers in 1 line
- ‚úÖ No code changes needed
- ‚úÖ Easy to test and maintain
- ‚úÖ Vendor-independent
- ‚úÖ Cost-optimized
- ‚úÖ Production-ready

**This is exactly what the user story asked for!** üéØ

